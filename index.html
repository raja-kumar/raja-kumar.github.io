<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'UA-7580334-2');
  </script>

  <title>Raja Kumar</title>
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css">
  
  <meta name="author" content="Raja Kumat">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="stylesheet" type="text/css" href="css/style.css">
  <link rel="icon" type="image/png" href="images/UCSC_icon.png">
</head>

<!-- <body onload="startPetCursor();"> -->
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:70%;vertical-align:middle">
              <p style="text-align:center">
                <name>Raja Kumar</name>
              </p>
              <p>
                I am a PhD student at University of Southern California advised by Prof. <a href = "https://viterbi.usc.edu/directory/faculty/Nevatia/Ramakant">Ram Nevatia</a>. I am broadly interested in Computer Vision and Deep Learning, with a focus on developing models for visual understanding in images and videos.
              </p>
              <p>  
                Before Joining USC, I completed my MS in Computer Science at the University of California Santa Cruz advised by Prof. <a href = "https://users.soe.ucsc.edu/~davis/">James Davis</a>. Previously, at Samsung Research, I worked with the on-device-AI team on developing and deploying Deep Learning Models on Samsung devices. I obtained my Bachelor's degree in Electrical Engineering from IIT Kharagpur.
              </p> 
              
              <p style="text-align:center">
                <a href = "mailto: rajasanwir.iitkgp@gmail.com">Email</a> &nbsp;/&nbsp;
                <a href="https://github.com/raja-kumar">GitHub</a> &nbsp;/&nbsp;
                <a href="https://scholar.google.com/citations?user=wlU2x_kAAAAJ&hl=en">Google Scholar</a> &nbsp;/&nbsp;
                <a href="https://www.linkedin.com/in/raja-kumar-58971010a/"> LinkedIn </a> &nbsp;/&nbsp;
                <!---<a href="https://www.instagram.com/raja_sanwir/"> instagram </a> &nbsp;/&nbsp;--->
                <!---<a href="https://twitter.com/RajaSanwir"> Twitter </a> &nbsp;/&nbsp;--->
                <a href="https://drive.google.com/file/d/1y4ZPvDkjdZNHk0c3kqe_9oFDEC1lPjy5/view?usp=sharing"> Resume (1 Page) </a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/raja_paris.jpg"><img style="width:70%;max-width:70%;border-radius:30%" alt="profile photo" src="images/raja_paris.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <hr>


<!--- This is the news/update section --->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
                <td style="padding:10px;width:100%;vertical-align:middle">
                    <heading>News/Updates</heading>
                </td>
            </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
            <ul>
                <li><strong>[Aug 2024]</strong> Joined USC as a CS PhD Student! </li>
                <li><strong>[Aug 2024]</strong> My work on few-shot 3D Gaussian splatting got accepted at S3DSGR @ ECCV'24!</li>
                <li><strong>[Apr 2024]</strong> Joined Flawless AI as Applied Science Intern 3D vision</li>
                <li><strong>[Mar 2024]</strong> Completed my MS in CS at UC Santa Cruz</li>
                <li><strong>[Oct 2023]</strong> Attended ICCV 2023 in Paris</li>
                <li><strong>[Aug 2023]</strong> My Paper on 3D face reconstruction got accepted at ICCV workshops 2023</li>
                <li><strong>[Sep 2022]</strong> Joined UCSC as CSE Master's student starting in Fall 2022</li>
                <li><strong>[Mar 2022]</strong> Joined Silverlabs recommendation team as an ML Engineer</li>
                <li><strong>[Apr 2021]</strong> My paper on quantization got accepted by IJCNN 2021</li>
                <li><strong>[Jun 2019]</strong> Joined Samsung Research on-device-AI team as an ML Engineer</li>
            </ul>
        </tr>
        </tbody></table>
      <hr>

<!--- this is the project/publication/patent section -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:10px;width:100%;vertical-align:middle">
              <heading>Projects/Papers</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

        
          <tr bgcolor="#ffffd0">
            <td style="padding:20px;width:35%;vertical-align:middle">
                <img src='images/eccvw.png' width="250"></div>
                    </td>
            <td width="75%" valign="middle">
                <p>
                <a href="https://arxiv.org/abs/2410.11080">
                    <papertitle>Paper: Few-shot Novel View Synthesis using Depth Aware 3D Gaussian Splatting</papertitle>
                </a>
                <br>
                <strong>Raja Kumar</strong>,
                <a href="https://www.vanshikavats.com/">Vanshika Vats</a>
                <br>
                <em>ECCV Workshops 2024</em>
                <br>
                </p>
                <div class="paper" id="eccvw_2024">
                    <a href="https://arxiv.org/abs/2410.11080">Pdf</a> /
                  <a href="https://github.com/raja-kumar/depth-aware-3DGS">code</a> 
                </div>
                <br>
            </td>
        </tr>
      </td>
    </tr>


          
          <tr>
            <td style="padding:20px;width:35%;vertical-align:middle">
                <img src='images/iccvw_2023.png' width="250"></div>
                    </td>
            <td width="75%" valign="middle">
                <p>
                <a href="https://arxiv.org/abs/2308.13903">
                    <papertitle>Paper: Disjoint Pose and Shape for 3D Face Reconstruction</papertitle>
                </a>
                <br>
                <strong>Raja Kumar</strong>,
                <a href="https://scholar.google.com/citations?user=2x71Xmh1U3gC&hl=en">Jiahao Luo</a>,
                <a href="https://users.soe.ucsc.edu/~pang/">Alex Pang</a>,
                <a href="https://users.soe.ucsc.edu/~davis/">James Davis</a>
                <br>
                <em>IEEE/CVF International Conference on Computer Vision (ICCV) Workshops</em>, 2023
                <br>
                </p>
                <!---
              <p>
                  Existing methods for 3D face reconstruction from a few casually captured images employ deep learning based models along with a 3D Morphable Model(3DMM) as face geometry prior. Structure From Motion(SFM), followed by Multi-View Stereo (MVS), on the other hand, uses dozens of high-resolution images to reconstruct accurate 3D faces.However, it produces noisy and stretched-out results with only two views available. In this paper, taking inspiration from both these methods, we propose an end-to-end pipeline that disjointly solves for pose and shape to make the optimization stable and accurate. We use a face shape prior to estimate face pose and use stereo matching followed by a 3DMM to solve for the shape. The proposed method achieves end-to-end topological consistency, enables iterative face pose refinement procedure, and show remarkable improvement on both quantitative and qualitative results over existing state-of-the-art methods.
                </p> 
              --->
                <div class="paper" id="iccvw_2023">
                    <a href="https://arxiv.org/abs/2308.13903">ArXiv</a>
                </div>
                <br>
            </td>
        </tr>
      </td>
    </tr>

    <tr bgcolor="#ffffd0">
            <td style="padding:20px;width:35%;vertical-align:middle">
                <img src='images/stereo_flame.png' width="250"></div>
                    </td>
            <td width="75%" valign="middle">
                <p>
                <a href="https://arxiv.org/abs/2308.13903">
                    <papertitle>Paper: 3D Face Reconstruction: Is model-based classic passive stereo competitive?</papertitle>
                </a>
                <br>
                <a href="https://scholar.google.com/citations?user=2x71Xmh1U3gC&hl=en">Jiahao Luo</a>,
                <strong>Raja Kumar</strong>,
                <a href="https://users.soe.ucsc.edu/~pang/">Alex Pang</a>,
                <a href="https://users.soe.ucsc.edu/~davis/">James Davis</a>
                <br>
                <em>Under Review</em>
                <br>
                </p>
              <!---  
              <p>
                  The highest quality 3D face reconstructions are produced using multi-view stereo methods, reporting errors below 0.5mm.
Unfortunately, these methods typically employ dozens of high-resolution cameras in a large laboratory capture gantry. In contrast,
state-of-the-art 3D face reconstructions using sophisticated deep learning models and few views are suited for casual mobile phone
imaging outside the lab and report a mean error of 1-2mm. This paper investigates whether classic passive stereo methods can be used in scenarios with only a few low-resolution images
available. We expect to find that it cannot since multi-view stereo performs well only when many high-resolution images are provided.
When only two low-resolution images are available, stereo produces very noisy results which are not directly usable. However, our
analysis shows that this visually noisy data has lower error than comparison state-of-the-art methods. We find that the visual artifacts
from stereo can be removed using a morphable face model to constrain face shape
                </p>
              --->
                <div class="paper" id="iccvw_2023">
                    <a href="https://drive.google.com/file/d/1ys0M4PCsLzBcKT83dCV6kSsmua8nDaQz/view?usp=sharing">Pdf</a>
                </div>
                <br>
            </td>
        </tr>
      </td>
    </tr>
          
          <tr>
        <td style="padding:20px;width:35%;vertical-align:middle">
            <img src='images/dense_2d.png' width="250"></div>
                </td>
        <td width="75%" valign="middle">
            <p>
            <a href="">
                <papertitle>Project: Dense 2D facial landmarks detector using 3D face model</papertitle>
            </a>
            <br>
              <strong>Raja Kumar</strong>
            <br>
            </p>
          <!---
            <p>
                Most of the existing face-alignment models detect the standard 68 face landmarks. However, there is a need of dense facial landmarks for tasks such 3d face reconstruction, face recognition etc. DAD-3DHeads proposed a dense 2d landmark detector based on 3D face reconstruction. However, their performance deteriorates when face is only a part of the image. To improve on this, I used mediapipe facial detector to detect the face, use the detected face to DADNet and then project back the detected landmarks in the original image coordinate. The Proposed pipeline is robust to all kind of input images.
            </p>
          --->
            <div class="paper" id="btp">
                <a href="https://github.com/raja-kumar/dense-face-alignment">code</a> 
                
            </div>
            <br>
        </td>
    </tr>

  <tr bgcolor="#ffffd0">
        <td style="padding:20px;width:35%;vertical-align:middle">
            <img src='images/pipeline.png' width="250"></div>
                </td>
        <td width="75%" valign="middle">
            <p>
            <a href="">
                <papertitle>Project: Task Oriented Conversational Modelling With Subjective Knowledge</papertitle>
            </a>
            <br>
              <strong>Raja Kumar</strong>
            <br>
            </p>
          <!---
            <p>
                Existing conversational models are handled by a database(DB) and API based systems. However, very often users’ questions require information that cannot be
handled by such systems. Nonetheless, answers to these questions are available
in the form of customer reviews and FAQs. DSTC-11 proposes a three stage
pipeline consisting of knowledge seeking turn detection, knowledge selection and
response generation to create a conversational model grounded on this subjective
knowledge. In this paper, we focus on improving the knowledge selection module
to enhance the overall system performance. In particular, we propose entity retrieval
methods which result in an accurate and faster knowledge search. Our proposed
Named Entity Recognition (NER) based entity retrieval method results in 7X faster
search compared to the baseline model. Additionally, we also explore a potential
keyword extraction method which can improve the accuracy of knowledge selection.
Preliminary results show a 4 % improvement in exact match score on knowledge
selection task.
            </p>
          --->
            <div class="paper" id="btp">
                <a href="https://arxiv.org/abs/2303.17695">pdf</a> /
                <a href="https://github.com/raja-kumar/knowledge-grounded-TODS">code</a> 
                
            </div>
            <br>
        </td>
    </tr>

        <tr>
            <td style="padding:20px;width:35%;vertical-align:middle">
                <img src='images/ijcnn_image.png' width="250"></div>
                    </td>
            <td width="75%" valign="middle">
                <p>
                <a href="https://ieeexplore.ieee.org/document/9533724">
                    <papertitle>Paper: Hybrid and non-uniform quantization methods using retro synthesis data for efficient inference</papertitle>
                </a>
                <br>
                <strong>Raja Kumar</strong>,
                <a href="">Tejpratap GVSL</a>,
                <a href="">Pradeep NS</a>,
                <br>
                <em>IJCNN</em>, 2021
                <br>
                </p>
              <!---
                <p>
                    We proposes a data-independent post-training quantization scheme that eliminates the need for training data. This is achieved by generating a faux dataset referred to as ‘Retro- Synthesis Data'.
                    We also introduced two futuristic variants of post- training quantization methods namely ‘Hybrid Quantization’ and ‘Non-Uniform Quantization’ for efficient and accurate inference.    
                </p>
              --->
                <div class="paper" id="ijcnn_2021">
                    <a href="data/Publication_IJCNN2021.pdf">pdf</a> /
                    <a href="https://github.com/raja-kumar/Hybrid_and_Non-uniform_quantization">code</a> 
                </div>
                <br>
            </td>
        </tr>
      </td>
    </tr>

    <tr bgcolor="#ffffd0">
        <td style="padding:20px;width:35%;vertical-align:middle">
            <img src='images/btp.png' width="250"></div>
                </td>
        <td width="75%" valign="middle">
            <p>
            <a href="">
                <papertitle>Project: Automatic Classification and Localisation of Defects in Hot-Rolled Steel Surfaces</papertitle>
            </a>
            <br>
              <strong>Raja Kumar</strong>
            <br>
            </p>
          <!---
            <p>
               This is my Bachelor's thesis aimed at developing an efficient DL solution for real-time detection and segmentation of defects in hot-rolled steel Surfaces. We train an R-CNN model in the frequency domain
using DCT to improve the accuracy achieving a mAP@0.5 score of 82.4.
            </p>
          --->
            <!---
          <div class="paper" id="btp">
                <a href="https://docs.google.com/presentation/d/1i4injnLzix94WWDP8WRy1UJ23-JG9-p7/edit?usp=share_link&ouid=113131068153245641189&rtpof=true&sd=true">pdf</a> 
                
            </div>
          --->
            <br>
        </td>
    </tr>
  </td>
</tr>
  </table>

  <hr>

<!--- this is the teaching section --->

 <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
                <td style="padding:10px;width:100%;vertical-align:middle">
                    <heading>Teaching Assistant</heading>
                </td>
            </tr>
        </tbody></table>
<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
            <ul>
              <li><strong>Introduction to Artificial Intelligence,</strong> Prof. <a href="https://viterbi.usc.edu/directory/faculty/Rajati/Mohammad-Reza">Mohammad Reza Rajati</a>, USC, Fall 2024 </li>
              <li><strong>Computer Systems and Assembly Programming,</strong> Prof. <a href="https://californiaconsultants.org/members/marcelo-siero/">Marcelo Siero</a>, UCSC, Winter, Fall 2023, Winter 2024</li>
              <li><strong>Introduction to Analysis of Algorithms,</strong> Prof. <a href="https://users.soe.ucsc.edu/~lodha/">Suresh Lodha</a>, UCSC, Summer 2023</li>
              <li><strong>Computer Architecture</strong> Prof. <a href="https://scottbeamer.net/">Scott Beamer</a>, UCSC,Spring 2023 </li>
            </ul>
        </tr>
        </tbody></table>
  <hr>


  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tr>
      <td style="padding:0px">
        <br>
        <p style="text-align:center;font-size:small;">
          Design and source code from <a style="font-size:small;" href="https://jonbarron.info">Jon Barron's website</a>
        </p>
      </td>
    </tr>
  </table>
</td>
</tr>
</table>

<script xml:space="preserve" language="JavaScript">
hideallbibs();
</script>

<!-- Google Analytics -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-131560165-1', 'auto');
  ga('send', 'pageview');
</script>
<!-- End Google Analytics -->

</body>

</html>
