<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'UA-7580334-2');
  </script>

  <title>Raja Kumar</title>
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css">
  
  <meta name="author" content="Raja Kumat">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="stylesheet" type="text/css" href="css/style.css">
  <link rel="icon" type="image/png" href="images/UCSC_icon.png">
</head>

<!-- <body onload="startPetCursor();"> -->
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:70%;vertical-align:middle">
              <p style="text-align:center">
                <name>Raja Kumar</name>
              </p>
              <p>  
                I am currently pursuing my Masters in Computer Science at the University of California Santa Cruz. I am currently a part of <a href = "https://sites.google.com/ucsc.edu/vis/home?authuser=0">VIS group</a> at UCSC guided by professor <a href = "https://users.soe.ucsc.edu/~davis/">James Davis</a>
              </p>
              <p>
                Previously, at Samsung Research, I worked with the on-device-AI team on developing and deploying Deep Learning Models on Samsung devices. I also worked on model compression techniques, DNN quantization in particular. Currently, I am doing research on 3D face reconstruction.
              </p>
                I obtained my Bachelor's degree in Electrical Engineering from IIT Kharagpur. 
              <p>
              <p><strong>Research Interest: 3D vision and its intersection with Computer Vision, Computer Graphics, and Machine Learning</strong></p>
              </p>
              <!--- <p style="text-align:center">
                </br>
                <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
                <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
                <a href="mailto:rkumar38@ucsc.edu"><i class="fa fa-envelope" style='font-size:30px'></i>&nbsp &nbsp
                <a href="https://scholar.google.com/citations?user=X3vVZPcAAAAJ&hl=en"><i class="ai ai-google-scholar ai-3x" style='font-size:28px'></i>&nbsp &nbsp
                <a href="https://github.com/cihangxie"><i class="fa fa-github" style='font-size:30px'></i>&nbsp &nbsp
                <a href="https://twitter.com/cihangxie?ref_src=twsrc%5Etfw" class="twitter-follow-button" data-show-count="false">Follow @cihangxie</a><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
              </p>
              --->
              <p style="text-align:center">
                <a href = "mailto: rajasanwir.iitkgp@gmail.com">Email</a> &nbsp;/&nbsp;
                <a href="https://github.com/raja-kumar">GitHub</a> &nbsp;/&nbsp;
                <a href="https://scholar.google.com/citations?user=wlU2x_kAAAAJ&hl=en">Google Scholar</a> &nbsp;/&nbsp;
                <a href="https://www.linkedin.com/in/raja-kumar-58971010a/"> LinkedIn </a> &nbsp;/&nbsp;
                <!---<a href="https://www.instagram.com/raja_sanwir/"> instagram </a> &nbsp;/&nbsp;--->
                <a href="https://twitter.com/RajaSanwir"> Twitter </a> &nbsp;/&nbsp;
                <a href="https://drive.google.com/file/d/1zprtsoMC-mPo1PCiYW_54xcq7Y6CAd5S/view?usp=sharing"> CV </a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/raja1.jpg"><img style="width:70%;max-width:70%;border-radius:30%" alt="profile photo" src="images/raja1.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

<!---- this is the perspective student section -->
        
        <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
                <td style="padding:10px;width:100%;vertical-align:middle">                    
                    <p><font color="orange"><strong>Prospective summer interns & visiting students</strong></font>: My group has a few positions for summer interns and visiting students. If you are interested, please send me an email with your CV, transcript, and publications (if any).</p>

                    <p><font color="red"><strong>Due to the large amount of emails I receive, I may not be able to respond to each one individually.</strong></font>

                    <p><font color="olive"><strong>Seminar</strong></font>: I am co-organizing a weekly seminar on <a href="https://vsehwag.github.io/SPML_seminar/">Security & Privacy in Machine Learning</a>. If you are interested, please <a href="https://groups.google.com/forum/#!forum/spml-seminars/join">join our mailing list</a> or <a href="https://calendar.google.com/calendar/u/0?cid=N2FwbTVxYzJsOGM2bXBiNGY4am1oMjNsdGNAZ3JvdXAuY2FsZW5kYXIuZ29vZ2xlLmNvbQ"> subscribe to our event calendar</a>.</p>
                </td>
            </tr>
        </tbody></table> -->
        <hr>


<!--- this is the project/publication/patent section -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:10px;width:100%;vertical-align:middle">
              <heading>Projects/Papers</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:35%;vertical-align:middle">
                <img src='images/iccvw_2023.png' width="250"></div>
                    </td>
            <td width="75%" valign="middle">
                <p>
                <a href="https://arxiv.org/abs/2308.13903">
                    <papertitle>Paper: Disjoint Pose and Shape for 3D Face Reconstruction</papertitle>
                </a>
                <br>
                <strong>Raja Kumar</strong>,
                <a href="https://scholar.google.com/citations?user=2x71Xmh1U3gC&hl=en">Jiahao Luo</a>,
                <a href="https://users.soe.ucsc.edu/~pang/">Alex Pang</a>,
                <a href="https://users.soe.ucsc.edu/~davis/">James Davis</a>
                <br>
                <em>IEEE/CVF International Conference on Computer Vision (ICCV) Workshops</em>, 2023
                <br>
                </p>
                <p>
                  Existing methods for 3D face reconstruction from a few casually captured images employ deep learning based models along with a 3D Morphable Model(3DMM) as face geometry prior. Structure From Motion(SFM), followed by Multi-View Stereo (MVS), on the other hand, uses dozens of high-resolution images to reconstruct accurate 3D faces.However, it produces noisy and stretched-out results with only two views available. In this paper, taking inspiration from both these methods, we propose an end-to-end pipeline that disjointly solves for pose and shape to make the optimization stable and accurate. We use a face shape prior to estimate face pose and use stereo matching followed by a 3DMM to solve for the shape. The proposed method achieves end-to-end topological consistency, enables iterative face pose refinement procedure, and show remarkable improvement on both quantitative and qualitative results over existing state-of-the-art methods.
                </p>
                <div class="paper" id="iccvw_2023">
                    <a href="https://arxiv.org/abs/2308.13903">ArXiv</a> /
                    <a href="">code (coming soon)</a> 
                </div>
                <br>
            </td>
        </tr>
      </td>
    </tr>

    <tr bgcolor="#ffffd0">
            <td style="padding:20px;width:35%;vertical-align:middle">
                <img src='images/stereo_flame.png' width="250"></div>
                    </td>
            <td width="75%" valign="middle">
                <p>
                <a href="https://arxiv.org/abs/2308.13903">
                    <papertitle>Paper: 3D Face Reconstruction: Is model-based classic passive stereo competitive?</papertitle>
                </a>
                <br>
                <a href="https://scholar.google.com/citations?user=2x71Xmh1U3gC&hl=en">Jiahao Luo</a>,
                <strong>Raja Kumar</strong>,
                <a href="https://users.soe.ucsc.edu/~pang/">Alex Pang</a>,
                <a href="https://users.soe.ucsc.edu/~davis/">James Davis</a>
                <br>
                <em>Under Review</em>
                <br>
                </p>
                <p>
                  The highest quality 3D face reconstructions are produced using multi-view stereo methods, reporting errors below 0.5mm.
Unfortunately, these methods typically employ dozens of high-resolution cameras in a large laboratory capture gantry. In contrast,
state-of-the-art 3D face reconstructions using sophisticated deep learning models and few views are suited for casual mobile phone
imaging outside the lab and report a mean error of 1-2mm. This paper investigates whether classic passive stereo methods can be used in scenarios with only a few low-resolution images
available. We expect to find that it cannot since multi-view stereo performs well only when many high-resolution images are provided.
When only two low-resolution images are available, stereo produces very noisy results which are not directly usable. However, our
analysis shows that this visually noisy data has lower error than comparison state-of-the-art methods. We find that the visual artifacts
from stereo can be removed using a morphable face model to constrain face shape
                </p>
                <div class="paper" id="iccvw_2023">
                    <a href="https://drive.google.com/file/d/1ys0M4PCsLzBcKT83dCV6kSsmua8nDaQz/view?usp=sharing">Pdf</a>
                </div>
                <br>
            </td>
        </tr>
      </td>
    </tr>
          
          <tr>
        <td style="padding:20px;width:35%;vertical-align:middle">
            <img src='images/dense_2d.png' width="250"></div>
                </td>
        <td width="75%" valign="middle">
            <p>
            <a href="">
                <papertitle>Project: Dense 2D facial landmarks detector using 3D face model</papertitle>
            </a>
            <br>
            </p>
            <p>
                Most of the existing face-alignment models detect the standard 68 face landmarks. However, there is a need of dense facial landmarks for tasks such 3d face reconstruction, face recognition etc. DAD-3DHeads proposed a dense 2d landmark detector based on 3D face reconstruction. However, their performance deteriorates when face is only a part of the image. To improve on this, I used mediapipe facial detector to detect the face, use the detected face to DADNet and then project back the detected landmarks in the original image coordinate. The Proposed pipeline is robust to all kind of input images.
            </p>
            <div class="paper" id="btp">
                <a href="https://github.com/raja-kumar/dense-face-alignment">code</a> 
                
            </div>
            <br>
        </td>
    </tr>

  <tr bgcolor="#ffffd0">
        <td style="padding:20px;width:35%;vertical-align:middle">
            <img src='images/pipeline.png' width="250"></div>
                </td>
        <td width="75%" valign="middle">
            <p>
            <a href="">
                <papertitle>Project: Task Oriented Conversational Modelling With Subjective Knowledge</papertitle>
            </a>
            <br>
            </p>
            <p>
                Existing conversational models are handled by a database(DB) and API based systems. However, very often users’ questions require information that cannot be
handled by such systems. Nonetheless, answers to these questions are available
in the form of customer reviews and FAQs. DSTC-11 proposes a three stage
pipeline consisting of knowledge seeking turn detection, knowledge selection and
response generation to create a conversational model grounded on this subjective
knowledge. In this paper, we focus on improving the knowledge selection module
to enhance the overall system performance. In particular, we propose entity retrieval
methods which result in an accurate and faster knowledge search. Our proposed
Named Entity Recognition (NER) based entity retrieval method results in 7X faster
search compared to the baseline model. Additionally, we also explore a potential
keyword extraction method which can improve the accuracy of knowledge selection.
Preliminary results show a 4 % improvement in exact match score on knowledge
selection task.
            </p>
            <div class="paper" id="btp">
                <a href="https://arxiv.org/abs/2303.17695">pdf</a> /
                <a href="https://github.com/raja-kumar/knowledge-grounded-TODS">code</a> 
                
            </div>
            <br>
        </td>
    </tr>

        <tr>
            <td style="padding:20px;width:35%;vertical-align:middle">
                <img src='images/ijcnn_image.png' width="250"></div>
                    </td>
            <td width="75%" valign="middle">
                <p>
                <a href="https://ieeexplore.ieee.org/document/9533724">
                    <papertitle>Paper: Hybrid and non-uniform quantization methods using retro synthesis data for efficient inference</papertitle>
                </a>
                <br>
                <strong>Raja Kumar</strong>,
                <a href="">Tejpratap GVSL</a>,
                <a href="">Pradeep NS</a>,
                <br>
                <em>IJCNN</em>, 2021
                <br>
                </p>
                <p>
                    We proposes a data-independent post-training quantization scheme that eliminates the need for training data. This is achieved by generating a faux dataset referred to as ‘Retro- Synthesis Data'.
                    We also introduced two futuristic variants of post- training quantization methods namely ‘Hybrid Quantization’ and ‘Non-Uniform Quantization’ for efficient and accurate inference.    
                </p>
                <div class="paper" id="ijcnn_2021">
                    <a href="data/Publication_IJCNN2021.pdf">pdf</a> /
                    <a href="https://github.com/raja-kumar/Hybrid_and_Non-uniform_quantization">code</a> 
                </div>
                <br>
            </td>
        </tr>
      </td>
    </tr>

    <tr bgcolor="#ffffd0">
        <td style="padding:20px;width:35%;vertical-align:middle">
            <img src='images/btp.png' width="250"></div>
                </td>
        <td width="75%" valign="middle">
            <p>
            <a href="">
                <papertitle>Project: Automatic Classification and Localisation of Defects in Hot-Rolled Steel Surfaces</papertitle>
            </a>
            <br>
            </p>
            <p>
               This is my Bachelor's thesis aimed at developing an efficient DL solution for real-time detection and segmentation of defects in hot-rolled steel Surfaces. We train an R-CNN model in the frequency domain
using DCT to improve the accuracy achieving a mAP@0.5 score of 82.4.
            </p>
            <!---
          <div class="paper" id="btp">
                <a href="https://docs.google.com/presentation/d/1i4injnLzix94WWDP8WRy1UJ23-JG9-p7/edit?usp=share_link&ouid=113131068153245641189&rtpof=true&sd=true">pdf</a> 
                
            </div>
          --->
            <br>
        </td>
    </tr>
  </td>
</tr>
  </table>

  <hr>

<!--- this is the teaching section --->

 <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
                <td style="padding:10px;width:100%;vertical-align:middle">
                    <heading>Teaching Assistant</heading>
                </td>
            </tr>
        </tbody></table>
<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
            <ul>
              <li><strong>[Fall 2023]</strong> CSE12: Computer Systems and Assembly Programming</li>
              <li><strong>[Summer 2023]</strong> CSE102: Introduction to Analysis of Algorithms</li>
              <li><strong>[Spring 2023]</strong> CSE120: Computer Architecture</li>
              <li><strong>[Winter 2023]</strong> CSE12: Computer Systems and Assembly Programming</li>
              <li><strong>[Fall 2022]</strong> CSE101: Introduction to data structures and algorithms</li>
               
               
            </ul>
        </tr>
        </tbody></table>
  <hr>
  

<!--- this is the recent news section -->
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
                <td style="padding:10px;width:100%;vertical-align:middle">
                    <heading>News/Updates</heading>
                </td>
            </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
            <ul>
                <li><strong>[Oct 2023]</strong> Attended ICCV 2023 in Paris</li>
                <li><strong>[Aug 2023]</strong> Our Paper on 3D face reconstruction got accepted at ICCV workshops 2023</li>
                <li><strong>[Sep 2022]</strong> I Joined UCSC as CSE Master's student starting in Fall 2022</li>
                <li><strong>[March 2022]</strong> I joined Silverlabs recommendation team as an ML Engineer</li>
                <li><strong>[April 2021]</strong> Our paper on quantization got accepted by IJCNN 2021</li>
                <li><strong>[June 2019]</strong> I joined Samsung Research on-device-AI team as an ML Engineer</li>
            </ul>
        </tr>
        </tbody></table>


  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tr>
      <td style="padding:0px">
        <br>
        <p style="text-align:center;font-size:small;">
          Design and source code from <a style="font-size:small;" href="https://jonbarron.info">Jon Barron's website</a>
        </p>
      </td>
    </tr>
  </table>
</td>
</tr>
</table>

<script xml:space="preserve" language="JavaScript">
hideallbibs();
</script>

<!-- Google Analytics -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-131560165-1', 'auto');
  ga('send', 'pageview');
</script>
<!-- End Google Analytics -->

</body>

</html>
